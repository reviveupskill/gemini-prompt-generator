```javascript
import { VertexAI } from '@google-cloud/vertexai';
import formidable from 'formidable';
import fs from 'fs';

export const config = {
    api: {
        bodyParser: false,
    },
};

const projectId = process.env.GCP_PROJECT_ID;
const location = process.env.GCP_LOCATION || 'us-central1';

const vertex_ai = new VertexAI({ project: projectId, location: location });

const textModel = vertex_ai.getGenerativeModel({
  model: 'gemini-pro',
});

const visionModel = vertex_ai.getGenerativeModel({
  model: 'gemini-pro-vision',
});

function imageToBase64(imagePath) {
  const imageBuffer = fs.readFileSync(imagePath);
  return imageBuffer.toString('base64');
}

export default async function handler(req, res) {
    if (req.method !== 'POST') {
        return res.status(405).json({ message: 'Only POST requests allowed' });
    }

    const form = formidable({ multiples: false, keepExtensions: true });

    form.parse(req, async (err, fields, files) => {
        if (err) {
            console.error('Form parsing error:', err);
            return res.status(500).json({ message: 'Error processing the request.' });
        }

        const text = Array.isArray(fields.text) ? fields.text[0] : fields.text;
        const imageFile = Array.isArray(files.image) ? files.image[0] : files.image;
        let generatedText = '';

        try {
            const requestParts = [];

            if (text && text.trim() !== '') {
              requestParts.push({ text: text });
            }

            if (imageFile) {
                const base64Image = imageToBase64(imageFile.filepath);
                requestParts.push({
                  inlineData: {
                    mimeType: imageFile.mimetype,
                    data: base664Image,
                  },
                });
                fs.unlinkSync(imageFile.filepath);
            }

            if (requestParts.length === 0) {
                return res.status(400).json({ message: 'Please provide text or an image.' });
            }

            let modelToUse;
            if (imageFile) {
              modelToUse = visionModel;
            } else {
              modelToUse = textModel;
            }

            const result = await modelToUse.generateContent({ contents: [{ parts: requestParts }] });
            const response = result.response;

            if (response.candidates && response.candidates.length > 0 &&
                response.candidates[0].content && response.candidates[0].content.parts &&
                response.candidates[0].content.parts.length > 0 &&
                response.candidates[0].content.parts[0].text) {
                generatedText = response.candidates[0].content.parts[0].text;
            } else {
                generatedText = 'No content generated by the model.';
            }

            res.status(200).json({ generatedText });

        } catch (error) {
            console.error('Vertex AI API Error:', error);
            res.status(500).json({ message: 'Failed to generate content.', error: error.message });
        }
    });
}
```
